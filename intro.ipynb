{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e4d423-43e9-4089-bf35-1b35d7e2915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_FLAG = \"--user\" #set user flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b82719-2ccf-4366-8abc-038be59a57ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install {USER_FLAG} google-cloud-aiplatform==1.4.3 --upgrade #install Google Cloud Pipeline Components\n",
    "!pip3 install {USER_FLAG} kfp google-cloud-pipeline-components==0.1.6 --upgrade #install kubeflow pipielines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d12b7c-e6dd-4f3b-8b48-226c38c7d3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#restart kernel after install\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c95f328-694d-4fab-9aa3-3d79fb1a6dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for correct installation, see kfp > v1.8\n",
    "!python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "!python3 -c \"import google_cloud_pipeline_components; print('google_cloud_pipeline_components version: {}'.format(google_cloud_pipeline_components.__version__))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9285bce6-4840-438c-b1e0-0e6498cb80ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get full project ID in case I forget number suffix e.g. 330104\n",
    "import os\n",
    "PROJECT_ID = \"\"\n",
    "\n",
    "# Get your Google Cloud project ID from gcloud\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID: \", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3c7edb-f8e2-4147-8303-bc21ad62b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store bucket name in variable\n",
    "BUCKET_NAME=\"gs://\" + PROJECT_ID + \"-bucket\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8857180a-ab09-42ee-9588-d85e59e88d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant kfp libraries\n",
    "from typing import NamedTuple\n",
    "\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.v2 import compiler\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, ClassificationMetrics, Metrics, component)\n",
    "from kfp.v2.google.client import AIPlatformClient\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import pipeline_jobs\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46697c05-80fe-4389-b98b-28243713fb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=%env PATH\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin\n",
    "REGION=\"us-west1-b\"\n",
    "\n",
    "#Cloud Storage path where artifacts are written\n",
    "PIPELINE_ROOT = f\"{BUCKET_NAME}/pipeline_root/\"\n",
    "PIPELINE_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8d3c04-4a50-4f2f-9c4b-c89720fac764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build example component which simply returns string input\n",
    "\n",
    "@component(base_image=\"python:3.9\", output_component_file=\"first-component.yaml\")\n",
    "def product_name(text: str) -> str:\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fed04f-e571-4b2e-9ef8-f234d364264d",
   "metadata": {},
   "source": [
    "@component decorator compiles function to a component when pipeline is run\n",
    "\n",
    "base_image specifices container image used by component\n",
    "\n",
    "output_component_file specifies yaml file to write the component to.  File is then written in the notebook instance and is shareable\n",
    "\n",
    "If you share it, have the recipient run this command:\n",
    "\n",
    "product_name_component = kfp.components.load_component_from_file('./first-component.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01adeec-90c9-4ea3-a18c-1da2790ebe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create emoji component to receive string and return tuple of input string with the emoji\n",
    "\n",
    "@component(packages_to_install=[\"emoji\"])\n",
    "def emoji(\n",
    "    text: str,\n",
    ") -> NamedTuple(\n",
    "    \"Outputs\",\n",
    "    [\n",
    "        (\"emoji_text\", str),  # Return parameters\n",
    "        (\"emoji\", str),\n",
    "    ],\n",
    "):\n",
    "    import emoji\n",
    "\n",
    "    emoji_text = text\n",
    "    emoji_str = emoji.emojize(':' + emoji_text + ':', use_aliases=True)\n",
    "    print(\"output one: {}; output_two: {}\".format(emoji_text, emoji_str))\n",
    "    return (emoji_text, emoji_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16a8fa8-3790-4b24-b564-1ad7c8beb80a",
   "metadata": {},
   "source": [
    "packages_to_install parameter tells component which external library dependencies are needed for this container e.g. emoji library\n",
    "\n",
    "\"Outputs\" is the name of the NamedTuple with keys \"emoji_text\" and \"emoji\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251d55e2-c092-43a7-82a9-b54f862bdbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component\n",
    "def build_sentence(\n",
    "    product: str,\n",
    "    emoji: str,\n",
    "    emojitext: str\n",
    ") -> str:\n",
    "    print(\"We completed the pipeline, hooray!\")\n",
    "    end_str = product + \" is \"\n",
    "    if len(emoji) > 0:\n",
    "        end_str += emoji\n",
    "    else:\n",
    "        end_str += emojitext\n",
    "    return(end_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612701d3-f8fd-40ec-a15f-28c21662ca29",
   "metadata": {},
   "source": [
    "This component consumes output of previous components anbd combines them to return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99702a65-ffad-42a9-ba70-6eb4891961ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"hello-world\",\n",
    "    description=\"An intro pipeline\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    ")\n",
    "\n",
    "# You can change the `text` and `emoji_str` parameters here to update the pipeline output\n",
    "def intro_pipeline(text: str = \"Vertex Pipelines\", emoji_str: str = \"sparkles\"):\n",
    "    product_task = product_name(text)\n",
    "    emoji_task = emoji(emoji_str)\n",
    "    consumer_task = build_sentence(\n",
    "        product_task.output,\n",
    "        emoji_task.outputs[\"emoji\"],\n",
    "        emoji_task.outputs[\"emoji_text\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6cd92d-c1ec-4c62-b96a-4239fa096f9c",
   "metadata": {},
   "source": [
    "@dsl.pipeline decorator sets up pipeline.  Gives a name, description, and root path where artifacts are written"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc8402c-0933-46e4-b232-adf412258779",
   "metadata": {},
   "source": [
    "product_task parameter takes product_name function as input (\"Vertex Pipelines\" is just the default value)\n",
    "emoji_task takes emoji function as input (\"sparkles\" is the default value)\n",
    "\n",
    "consumer_task takes the build_sentence function and uses the the outputs of previous components' outputs as parameters for product, emoji, and emojitext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f620ec0a-5dd3-406d-8d06-36dc6a66e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=intro_pipeline, package_path=\"intro_pipeline_job.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce71572e-ff94-46c0-8a9b-d414bd87d6e7",
   "metadata": {},
   "source": [
    "^compiles pipeline and generates JSON file that will be used to run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a680ab8b-111d-4c2d-a4f4-b4694392e623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b292b45-6314-40ef-a6a3-5881e97ae120",
   "metadata": {},
   "source": [
    "^ creates TIMESTAMP used in job ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603e6f80-d2f5-4e63-bb7f-9e9c8071f644",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = pipeline_jobs.PipelineJob(\n",
    "    display_name=\"hello-world-pipeline\",\n",
    "    template_path=\"intro_pipeline_job.json\",\n",
    "    job_id=\"hello-world-pipeline-{0}\".format(TIMESTAMP),\n",
    "    enable_caching=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c496cc-ea50-46b2-a081-e525dd01e73a",
   "metadata": {},
   "source": [
    "^defines job with name, path to JSON file from ablove, and jobID with timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "552549e6-fef2-420e-9014-e39502d8ebf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/508427162175/locations/us-central1/pipelineJobs/hello-world-pipeline-20211025045917 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob run completed. Resource name: projects/508427162175/locations/us-central1/pipelineJobs/hello-world-pipeline-20211025045917\n"
     ]
    }
   ],
   "source": [
    "job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f01051c0-f6d7-4cd2-bc70-d31941dd0fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"gcr.io/deeplearning-platform-release/tf2-cpu.2-3:latest\",\n",
    "    output_component_file=\"tables_eval_component.yaml\", # Optional: you can use this to load the component later\n",
    "    packages_to_install=[\"google-cloud-aiplatform\"],\n",
    ")\n",
    "def classif_model_eval_metrics(\n",
    "    project: str,\n",
    "    location: str,  # \"us-central1\",\n",
    "    api_endpoint: str,  # \"us-central1-aiplatform.googleapis.com\",\n",
    "    thresholds_dict_str: str, #0.95 value for ROC curve, compare model to this metric before deployment\n",
    "    model: Input[Model],\n",
    "    metrics: Output[Metrics],\n",
    "    metricsc: Output[ClassificationMetrics],\n",
    ") -> NamedTuple(\"Outputs\", [(\"dep_decision\", str)]):  # Return parameter.\n",
    "\n",
    "    \"\"\"This function renders evaluation metrics for an AutoML Tabular classification model.\n",
    "    It retrieves the classification model evaluation generated by the AutoML Tabular training\n",
    "    process, does some parsing, and uses that info to render the ROC curve and confusion matrix\n",
    "    for the model. It also uses given metrics threshold information and compares that to the\n",
    "    evaluation results to determine whether the model is sufficiently accurate to deploy.\n",
    "    \"\"\"\n",
    "    import json\n",
    "    import logging\n",
    "\n",
    "    from google.cloud import aiplatform\n",
    "#************************************************************************************************************************\n",
    "    # Fetch model eval info\n",
    "    def get_eval_info(client, model_name):\n",
    "        from google.protobuf.json_format import MessageToDict\n",
    "\n",
    "        response = client.list_model_evaluations(parent=model_name)\n",
    "        metrics_list = []\n",
    "        metrics_string_list = []\n",
    "        for evaluation in response:\n",
    "            print(\"model_evaluation\")\n",
    "            print(\" name:\", evaluation.name)\n",
    "            print(\" metrics_schema_uri:\", evaluation.metrics_schema_uri)\n",
    "            metrics = MessageToDict(evaluation._pb.metrics)\n",
    "            for metric in metrics.keys():\n",
    "                logging.info(\"metric: %s, value: %s\", metric, metrics[metric])\n",
    "            metrics_str = json.dumps(metrics)\n",
    "            metrics_list.append(metrics)\n",
    "            metrics_string_list.append(metrics_str)\n",
    "\n",
    "        return (\n",
    "            evaluation.name,\n",
    "            metrics_list,\n",
    "            metrics_string_list,\n",
    "        )\n",
    "\n",
    "    # Use the given metrics threshold(s) to determine whether the model is \n",
    "    # accurate enough to deploy.\n",
    "    def classification_thresholds_check(metrics_dict, thresholds_dict):\n",
    "        for k, v in thresholds_dict.items():\n",
    "            logging.info(\"k {}, v {}\".format(k, v))\n",
    "            if k in [\"auRoc\", \"auPrc\"]:  # higher is better\n",
    "                if metrics_dict[k] < v:  # if under threshold, don't deploy\n",
    "                    logging.info(\n",
    "                        \"{} < {}; returning False\".format(metrics_dict[k], v)\n",
    "                    )\n",
    "                    return False\n",
    "        logging.info(\"threshold checks passed.\")\n",
    "        return True\n",
    "#************************************************************************************************************************\n",
    "\n",
    "    def log_metrics(metrics_list, metricsc):\n",
    "        test_confusion_matrix = metrics_list[0][\"confusionMatrix\"]\n",
    "        logging.info(\"rows: %s\", test_confusion_matrix[\"rows\"])\n",
    "\n",
    "        # log the ROC curve\n",
    "        fpr = []\n",
    "        tpr = []\n",
    "        thresholds = []\n",
    "        for item in metrics_list[0][\"confidenceMetrics\"]:\n",
    "            fpr.append(item.get(\"falsePositiveRate\", 0.0))\n",
    "            tpr.append(item.get(\"recall\", 0.0))\n",
    "            thresholds.append(item.get(\"confidenceThreshold\", 0.0))\n",
    "        print(f\"fpr: {fpr}\")\n",
    "        print(f\"tpr: {tpr}\")\n",
    "        print(f\"thresholds: {thresholds}\")\n",
    "        metricsc.log_roc_curve(fpr, tpr, thresholds)\n",
    "\n",
    "        # log the confusion matrix\n",
    "        annotations = []\n",
    "        for item in test_confusion_matrix[\"annotationSpecs\"]:\n",
    "            annotations.append(item[\"displayName\"])\n",
    "        logging.info(\"confusion matrix annotations: %s\", annotations)\n",
    "        metricsc.log_confusion_matrix(\n",
    "            annotations,\n",
    "            test_confusion_matrix[\"rows\"],\n",
    "        )\n",
    "\n",
    "        # log textual metrics info as well\n",
    "        for metric in metrics_list[0].keys():\n",
    "            if metric != \"confidenceMetrics\":\n",
    "                val_string = json.dumps(metrics_list[0][metric])\n",
    "                metrics.log_metric(metric, val_string)\n",
    "        # metrics.metadata[\"model_type\"] = \"AutoML Tabular classification\"\n",
    "\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    aiplatform.init(project=project)\n",
    "    # extract the model resource name from the input Model Artifact\n",
    "    model_resource_path = model.uri.replace(\"aiplatform://v1/\", \"\")\n",
    "    logging.info(\"model path: %s\", model_resource_path)\n",
    "\n",
    "    client_options = {\"api_endpoint\": api_endpoint}\n",
    "    # Initialize client that will be used to create and send requests.\n",
    "    client = aiplatform.gapic.ModelServiceClient(client_options=client_options)\n",
    "    eval_name, metrics_list, metrics_str_list = get_eval_info(\n",
    "        client, model_resource_path\n",
    "    )\n",
    "    logging.info(\"got evaluation name: %s\", eval_name)\n",
    "    logging.info(\"got metrics list: %s\", metrics_list)\n",
    "    log_metrics(metrics_list, metricsc)\n",
    "\n",
    "#************************************************************************************************************************\n",
    "    thresholds_dict = json.loads(thresholds_dict_str)\n",
    "    deploy = classification_thresholds_check(metrics_list[0], thresholds_dict)\n",
    "    if deploy:\n",
    "        dep_decision = \"true\"\n",
    "    else:\n",
    "        dep_decision = \"false\"\n",
    "    logging.info(\"deployment decision is %s\", dep_decision)\n",
    "#************************************************************************************************************************\n",
    "    return (dep_decision,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7911f1-346f-4518-a7a5-6826b9f6b54d",
   "metadata": {},
   "source": [
    "^Custom component \n",
    "\n",
    "As input, this pipeline takes some metadata on our Cloud project, the resulting trained model (we'll define this component later), the model's evaluation metrics, and a thresholds_dict_str (e.g. 0.95 threshold for ROC curve)\n",
    "\n",
    "Component returns a string indicating whether or not to deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec196200-aaec-47d1-9b7a-0cdabbeb95c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automl-beans1635141047\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "DISPLAY_NAME = 'automl-beans{}'.format(str(int(time.time())))\n",
    "print(DISPLAY_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07ddf70-4473-4786-a8bf-567b25d5f856",
   "metadata": {},
   "source": [
    "^Display name for pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cef12879-e79a-4dbc-abcc-978f8a259ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name=\"automl-tab-beans-training-v2\",\n",
    "                  pipeline_root=PIPELINE_ROOT)\n",
    "def pipeline(\n",
    "    bq_source: str = \"bq://aju-dev-demos.beans.beans1\",\n",
    "    display_name: str = DISPLAY_NAME,\n",
    "    project: str = PROJECT_ID,\n",
    "    gcp_region: str = \"us-central1\",\n",
    "    api_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
    "    thresholds_dict_str: str = '{\"auRoc\": 0.95}',\n",
    "):\n",
    "    #TabularDatasetCreateOp\n",
    "    #creates tabular dataset in Vertex AI given a source from Cloud Sorage or GBQ\n",
    "    dataset_create_op = gcc_aip.TabularDatasetCreateOp(\n",
    "        project=project, display_name=display_name, bq_source=bq_source\n",
    "    )\n",
    "\n",
    "    #AutoMLTabularTrainingJobRunOp \n",
    "    #creates AutoML training job for tabular dataset\n",
    "    training_op = gcc_aip.AutoMLTabularTrainingJobRunOp(\n",
    "        project=project,\n",
    "        display_name=display_name,\n",
    "        optimization_prediction_type=\"classification\", #optimization_prediction_type is the model type i.e. classification\n",
    "        budget_milli_node_hours=1000, #how long to run training for\n",
    "        column_transformations=[ #column types and names\n",
    "            {\"numeric\": {\"column_name\": \"Area\"}},\n",
    "            {\"numeric\": {\"column_name\": \"Perimeter\"}},\n",
    "            {\"numeric\": {\"column_name\": \"MajorAxisLength\"}},\n",
    "            {\"numeric\": {\"column_name\": \"MinorAxisLength\"}},\n",
    "            {\"numeric\": {\"column_name\": \"AspectRation\"}},\n",
    "            {\"numeric\": {\"column_name\": \"Eccentricity\"}},\n",
    "            {\"numeric\": {\"column_name\": \"ConvexArea\"}},\n",
    "            {\"numeric\": {\"column_name\": \"EquivDiameter\"}},\n",
    "            {\"numeric\": {\"column_name\": \"Extent\"}},\n",
    "            {\"numeric\": {\"column_name\": \"Solidity\"}},\n",
    "            {\"numeric\": {\"column_name\": \"roundness\"}},\n",
    "            {\"numeric\": {\"column_name\": \"Compactness\"}},\n",
    "            {\"numeric\": {\"column_name\": \"ShapeFactor1\"}},\n",
    "            {\"numeric\": {\"column_name\": \"ShapeFactor2\"}},\n",
    "            {\"numeric\": {\"column_name\": \"ShapeFactor3\"}},\n",
    "            {\"numeric\": {\"column_name\": \"ShapeFactor4\"}},\n",
    "            {\"categorical\": {\"column_name\": \"Class\"}},\n",
    "        ],\n",
    "        dataset=dataset_create_op.outputs[\"dataset\"], #pointer for dataset, pass in output of previous component above\n",
    "        target_column=\"Class\", #choose target column\n",
    "    )\n",
    "    \n",
    "#     def classif_model_eval_metrics(\n",
    "#     project: str,\n",
    "#     location: str,  # \"us-central1\",\n",
    "#     api_endpoint: str,  # \"us-central1-aiplatform.googleapis.com\",\n",
    "#     thresholds_dict_str: str, #0.95 value for ROC curve, compare model to this metric before deployment\n",
    "#     model: Input[Model],\n",
    "#     metrics: Output[Metrics],\n",
    "#     metricsc: Output[ClassificationMetrics],\n",
    "        \n",
    "    model_eval_task = classif_model_eval_metrics( #save model judgment using model\n",
    "        project,\n",
    "        gcp_region,\n",
    "        api_endpoint,\n",
    "        thresholds_dict_str,\n",
    "        training_op.outputs[\"model\"], #outputs of previous component\n",
    "    )\n",
    "\n",
    "    #only proceed in pipeline if model meets constraint\n",
    "    with dsl.Condition(\n",
    "        model_eval_task.outputs[\"dep_decision\"] == \"true\",\n",
    "        name=\"deploy_decision\",\n",
    "    ):\n",
    "        #ModelDeployOp deploys model to endpoint in Vertex AI\n",
    "        deploy_op = gcc_aip.ModelDeployOp(  # noqa: F841\n",
    "            model=training_op.outputs[\"model\"], #use outputs of previous component\n",
    "            project=project,\n",
    "            machine_type=\"n1-standard-4\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2947ffb2-87e3-45ee-9a94-e0027e8c0981",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline, package_path=\"tab_classif_pipeline.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ee5df04-420f-4ded-9fd4-0306c9c2c7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define pipeline job\n",
    "\n",
    "ml_pipeline_job = pipeline_jobs.PipelineJob(\n",
    "    display_name=\"automl-tab-beans-training\",\n",
    "    template_path=\"tab_classif_pipeline.json\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    parameter_values={\"project\": PROJECT_ID, \"display_name\": DISPLAY_NAME},\n",
    "    enable_caching=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcf0212-4a6d-4bc8-bd4c-adf16dbe2efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/508427162175/locations/us-central1/pipelineJobs/automl-tab-beans-training-v2-20211025061117\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/508427162175/locations/us-central1/pipelineJobs/automl-tab-beans-training-v2-20211025061117')\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/automl-tab-beans-training-v2-20211025061117?project=508427162175\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/508427162175/locations/us-central1/pipelineJobs/automl-tab-beans-training-v2-20211025061117 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/508427162175/locations/us-central1/pipelineJobs/automl-tab-beans-training-v2-20211025061117 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/508427162175/locations/us-central1/pipelineJobs/automl-tab-beans-training-v2-20211025061117 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/508427162175/locations/us-central1/pipelineJobs/automl-tab-beans-training-v2-20211025061117 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/508427162175/locations/us-central1/pipelineJobs/automl-tab-beans-training-v2-20211025061117 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "ml_pipeline_job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad80a8f4-f853-4f5d-9006-4cf5294a67e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m81"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
